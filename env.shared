LLM_PROVIDER="ollama"

SKIP_LANG_TRANSLATOR=False

DEFAULT_TRANSLATION_LANG="French"
DEFAULT_EXPORT_TRANSCRIBER="distil_whisper"

## llamacpp-python
LLAMACPP_API_HOST="http://192.168.0.29:8004"
## ollama
OLLAMA_API_HOST="http://192.168.0.18:12345"

## data storage
HISTORY_DB="resources/historydb"
SESSION_LOGS="workspace/session_logs"
DOWNLOADS_DIR="workspace/downloads"

## huggingface models
HF_CACHE_DIR="resources/models"

## Utility Models
LANG_TRANSLATOR="facebook/seamless-m4t-v2-large"
DISTIL_WHISPER="distil-whisper/distil-large-v2"
FASTER_WHISPER="Systran/faster-whisper-large-v3"

## LLM Models
HF_MM_REPO_ID="cjpais/llava-1.6-mistral-7b-gguf"
HF_MM_REPO_MODEL_FILE="llava-v1.6-mistral-7b.Q4_K_M.gguf"
HF_MM_REPO_PROJECT_FILE="mmproj-model-f16.gguf"

## mistral 7b
HF_REPO_ID="TheBloke/Mistral-7B-Instruct-v0.2-GGUF"
HF_REPO_MODEL_FILE="mistral-7b-instruct-v0.2.Q4_K_M.gguf"

